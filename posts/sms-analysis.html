<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta content="initial-scale=1, width=device-width" name="viewport"/><link href="https://www.nigel-schuster.de/posts/sms-analysis" rel="canonical"/><link href="/favicon/apple-touch-icon.png" sizes="180x180"/><link href="/favicon/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/><link href="/favicon/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/><link href="/favicon/site.webmanifest" rel="manifest"/><link color="#000000" href="/favicon/safari-pinned-tab.svg"/><link href="/favicon/favicon.ico" rel="icon"/><meta content="#000000" name="msapplication-TileColor"/><meta content="/favicon/browserconfig.xml" name="msapplication-config"/><meta content="#000" name="theme-color"/><link href="/feed.xml" rel="alternate" type="application/rss+xml"/><script async="" data-goatcounter="https://nigel.goatcounter.com/count" data-goatcounter-settings="{}" src="//gc.zgo.at/count.js"></script><title>Messaging Analysis and Visualization</title><meta content="" name="description"/><meta content="Messaging Analysis and Visualization" property="og:title"/><meta content="" property="og:description"/><meta content="article" property="og:type"/><meta content="en_US" property="og:locale"/><meta name="next-head-count" content="20"/><meta content="#1976d2" name="theme-color"/><link rel="preload" href="/_next/static/css/727973242bb33abd.css" as="style"/><link rel="stylesheet" href="/_next/static/css/727973242bb33abd.css" data-n-g=""/><link rel="preload" href="/_next/static/css/2aec7fdc1f1ca4ae.css" as="style"/><link rel="stylesheet" href="/_next/static/css/2aec7fdc1f1ca4ae.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-74c5770b086bb7e4.js" defer=""></script><script src="/_next/static/chunks/framework-0affefb16308ed4d.js" defer=""></script><script src="/_next/static/chunks/main-3c174807d57aab30.js" defer=""></script><script src="/_next/static/chunks/pages/_app-ddd9b80c68cb3369.js" defer=""></script><script src="/_next/static/chunks/195-8c007b11d2e13cce.js" defer=""></script><script src="/_next/static/chunks/832-5cc8cdaf50734c93.js" defer=""></script><script src="/_next/static/chunks/158-6de149606ba6d2b0.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-50fd91f26d9c459a.js" defer=""></script><script src="/_next/static/5jr8GNds5__xtcSePFMSK/_buildManifest.js" defer=""></script><script src="/_next/static/5jr8GNds5__xtcSePFMSK/_ssgManifest.js" defer=""></script><script src="/_next/static/5jr8GNds5__xtcSePFMSK/_middlewareManifest.js" defer=""></script><style data-emotion="css-global o6gwfi">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:rgba(0, 0, 0, 0.87);font-family:"Roboto","Helvetica","Arial",sans-serif;font-weight:400;font-size:1rem;line-height:1.5;letter-spacing:0.00938em;background-color:#fff;}@media print{body{background-color:#fff;}}body::backdrop{background-color:#fff;}</style><style data-emotion="css "></style></head><body><div id="__next"><div class="min-h-screen"><main><div class="MuiContainer-root MuiContainer-maxWidthLg css-1qsxih2"><a class="MuiTypography-root MuiTypography-h1 MuiLink-root MuiLink-underlineNone css-5ix4ge" href="/">Yet another SWE Blog.</a><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation1 MuiCard-root css-s18byi"><img class="MuiCardMedia-root MuiCardMedia-media MuiCardMedia-img css-rhsghg"/><div class="MuiCardContent-root css-1qw96cp"><div class="MuiBox-root css-k008qs"><div class="MuiBox-root css-i9gxme"><h1 class="MuiTypography-root MuiTypography-h3 css-lq9rk4">Messaging Analysis and Visualization</h1></div><div class="MuiBox-root css-56sg73"><div class="MuiButtonBase-root MuiChip-root MuiChip-filled MuiChip-sizeMedium MuiChip-colorDefault MuiChip-clickable MuiChip-clickableColorDefault MuiChip-filledDefault css-genwvd" tabindex="0" href="/author/nigel-schuster"><div class="MuiAvatar-root MuiAvatar-circular MuiChip-avatar MuiChip-avatarMedium MuiChip-avatarColorDefault css-3i9vrz"><img alt="Nigel Schuster" src="https://media.graphassets.com/resize=fit:crop,height:100,width:100/1bF1qLxsSbElgNK5x6t6" class="MuiAvatar-img css-1hy9t21"/></div><span class="MuiChip-label MuiChip-labelMedium css-9iedg7">Nigel Schuster</span></div></div></div><p>About a year ago I attended a <!-- --><a href="https://www.meetup.com/it-IT/NYC-D3-JS/events/236673854/">Meetup on D3.js<!-- --></a>. The first talk by <!-- --><a href="https://github.com/mdezube">Michael Dezube<!-- --></a> was on using machine learning to analyze text messages and visualize the results. Today I want to walk through all the awesomeness we have in this project.<!-- --></p>
<!-- --><h1>Demo<!-- --></h1>
<!-- --><p>The first chart we see is this
<!-- --><img src="https://media.graphcms.com/BOw9T1zYQ4eUKUCZTK9d" alt="texting per month"/></p>
<!-- --><p>Here it shows us our messaging habits over the years. Fascinating how it varies! But let&#x27;s dive deeper. The important question is: Who did we message? We can display the top N people:
<!-- --><img src="https://media.graphcms.com/kr0XNn7cQY21lkD2C1te" alt="top people messaged with"/></p>
<!-- --><p>But who did we message and when?
<!-- --><img src="https://media.graphcms.com/pkGf8kxTnevn7OiELmvw" alt="people messaged over time"/></p>
<!-- --><p>This graph is great! It&#x27;s almost a history of my life. Looking back at it, I can see when I made friendships and how they were developing. This is probably my favorite visualization!<!-- --></p>
<!-- --><p>After that we have a word cloud and a tree for visualizing conversations, but it&#x27;s a little too personal for me to post online.<!-- --></p>
<!-- --><p>Later in the Jupyter notebook we find a chart that shows us our top words over the years, accounting for the relative frequency in other years:
<!-- --><img src="https://media.graphcms.com/bBSQzlOjSneomJ3MtO2C" alt="words over the years"/></p>
<!-- --><p>Here we see me moving to the US, but also how I was interacting. The blacked out sections are names of people. Fascinating who I was talking about ðŸ˜‰.<!-- --></p>
<!-- --><p>This project has not seen any attention in the last months, but there is still so much more to explore.<!-- --></p>
<!-- --><h1>How it works<!-- --></h1>
<!-- --><p>We start by loading the data into our notebook<!-- --></p>
<!-- --><pre><code class="hljs language-python"><span class="hljs-keyword">import<!-- --></span> iphone_connector
iphone_connector.initialize()
fully_merged_messages_df, address_book_df = iphone_connector.get_cleaned_fully_merged_messages()
<!-- --></code></pre>
<!-- --><p>The connector does all the heavy lifting. The iphone_connector accesses the latest iPhone backup and reads all text messages from its database. The facebook_connector uses fbchat_archive_parser to read a user&#x27;s archive of chat messages. Now we have fully_merged_messages_df and address_book_df, both of which are <!-- --><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html">Pandas Dataframes<!-- --></a>.<!-- --></p>
<!-- --><p>Once we have the messages we can create the heatmap. First we group our messages by month:<!-- --></p>
<!-- --><pre><code class="hljs language-python">month_year_messages = pd.DataFrame(df[<!-- --><span class="hljs-string">&#x27;date&#x27;<!-- --></span>])
month_year_messages[<!-- --><span class="hljs-string">&#x27;year&#x27;<!-- --></span>] = month_year_messages.apply(<!-- --><span class="hljs-keyword">lambda<!-- --></span> row: row.date.year, axis=<!-- --><span class="hljs-number">1<!-- --></span>)
month_year_messages[<!-- --><span class="hljs-string">&#x27;month&#x27;<!-- --></span>] = month_year_messages.apply(<!-- --><span class="hljs-keyword">lambda<!-- --></span> row: row.date.month, axis=<!-- --><span class="hljs-number">1<!-- --></span>)
<!-- --></code></pre>
<!-- --><p>Then we create a pivot table that contains the number of messages per month.<!-- --></p>
<!-- --><pre><code class="hljs language-python">month_year_messages_pivot = month_year_messages.pivot_table(index=<!-- --><span class="hljs-string">&#x27;year&#x27;<!-- --></span>,columns=<!-- --><span class="hljs-string">&#x27;month&#x27;<!-- --></span>,aggfunc=<!-- --><span class="hljs-built_in">len<!-- --></span>, dropna=<!-- --><span class="hljs-literal">True<!-- --></span>)
month_year_messages_pivot = month_year_messages_pivot[month_year_messages_pivot.count(axis=<!-- --><span class="hljs-number">1<!-- --></span>) == <!-- --><span class="hljs-number">12<!-- --></span>]
<!-- --></code></pre>
<!-- --><p>After that we feed the data into the plotting tool.<!-- --></p>
<!-- --><p>Next we want to create the barchart to see who we have messaged the most in the past. We group the messages by message partner and count how many you sent and received.<!-- --></p>
<!-- --><pre><code class="hljs language-python"><span class="hljs-keyword">def<!-- --></span> <!-- --><span class="hljs-title hljs-function">get_message_counts<!-- --></span>(<!-- --><span class="hljs-params">dataframe<!-- --></span>):
    <!-- --><span class="hljs-keyword">return<!-- --></span> pd.Series({
      <!-- --><span class="hljs-string">&#x27;Texts sent&#x27;<!-- --></span>: dataframe[dataframe.is_from_me == <!-- --><span class="hljs-number">1<!-- --></span>].shape[<!-- --><span class="hljs-number">0<!-- --></span>],
      <!-- --><span class="hljs-string">&#x27;Texts received&#x27;<!-- --></span>: dataframe[dataframe.is_from_me == <!-- --><span class="hljs-number">0<!-- --></span>].shape[<!-- --><span class="hljs-number">0<!-- --></span>],
      <!-- --><span class="hljs-string">&#x27;Texts exchanged&#x27;<!-- --></span>: dataframe.shape[<!-- --><span class="hljs-number">0<!-- --></span>]
    })
messages_grouped = fully_merged_messages_df.groupby(<!-- --><span class="hljs-string">&#x27;full_name&#x27;<!-- --></span>).apply(get_message_counts)
messages_grouped = messages_grouped.sort_values(by=<!-- --><span class="hljs-string">&#x27;Texts exchanged&#x27;<!-- --></span>, ascending=<!-- --><span class="hljs-literal">False<!-- --></span>)
<!-- --></code></pre>
<!-- --><p>By combining the ideas from the two charts above we can create the chart that shows our interactions with friends over time. We select our TOP_N friends and count how many messages we sent them each month.<!-- --></p>
<!-- --><pre><code class="hljs language-python">sliced_df = fully_merged_messages_df[fully_merged_messages_df.full_name.isin(messages_grouped.head(TOP_N).index)]
grouped_by_month = sliced_df.groupby([
    sliced_df.apply(<!-- --><span class="hljs-keyword">lambda<!-- --></span> x: x.date.strftime(<!-- --><span class="hljs-string">&#x27;%Y/%m&#x27;<!-- --></span>), axis=<!-- --><span class="hljs-number">1<!-- --></span>),
    <!-- --><span class="hljs-string">&#x27;full_name&#x27;<!-- --></span>]
)[<!-- --><span class="hljs-string">&#x27;text&#x27;<!-- --></span>].count().to_frame()
<!-- --></code></pre>
<!-- --><p>After that we graph it using <!-- --><a href="https://github.com/d3/d3">D3.js<!-- --></a>.<!-- --></p>
<!-- --><p>The final chart - our most used words per year - requires us to dive into NLP. We&#x27;ll be using Tfidf (term-frequency times inverse document-frequency) to calculate the relevance of each word.<!-- --></p>
<!-- --><pre><code class="hljs language-python"><span class="hljs-keyword">from<!-- --></span> sklearn.feature_extraction.text <!-- --><span class="hljs-keyword">import<!-- --></span> TfidfVectorizer
<!-- --><span class="hljs-keyword">from<!-- --></span> nltk <!-- --><span class="hljs-keyword">import<!-- --></span> tokenize
vectorizer = TfidfVectorizer(preprocessor=clean_text, tokenizer=tokenize.WordPunctTokenizer().tokenize, ngram_range=(<!-- --><span class="hljs-number">1<!-- --></span>, <!-- --><span class="hljs-number">2<!-- --></span>), max_df=<!-- --><span class="hljs-number">.9<!-- --></span>, max_features=<!-- --><span class="hljs-number">50000<!-- --></span>)
grouped_by_name = fully_merged_messages_df[fully_merged_messages_df.is_from_me == <!-- --><span class="hljs-number">0<!-- --></span>].groupby(<!-- --><span class="hljs-string">&#x27;full_name&#x27;<!-- --></span>)[<!-- --><span class="hljs-string">&#x27;text&#x27;<!-- --></span>].apply(<!-- --><span class="hljs-keyword">lambda<!-- --></span> x: <!-- --><span class="hljs-string">&#x27; &#x27;<!-- --></span>.join(x)).to_frame()
vectorizer.fit(grouped_by_name.text)
<!-- --></code></pre>
<!-- --><p>The above code identifies the most relevant word for a certain chat partner, but important is, that it trains our TfidfVectorizer. We can now use it to find the prominence of a word in a given year.<!-- --></p>
<!-- --><pre><code class="hljs language-python">grouper = slice_of_texts_df.date.apply(<!-- --><span class="hljs-keyword">lambda<!-- --></span> x: x.year)
grouped_by_year = slice_of_texts_df.groupby(grouper).apply(
  <!-- --><span class="hljs-keyword">lambda<!-- --></span> row: pd.Series({<!-- --><span class="hljs-string">&#x27;count&#x27;<!-- --></span>: <!-- --><span class="hljs-built_in">len<!-- --></span>(row.date), <!-- --><span class="hljs-string">&#x27;text&#x27;<!-- --></span>: <!-- --><span class="hljs-string">&#x27; &#x27;<!-- --></span>.join(row.text)})
)
grouped_by_year_tfidf = vectorizer.transform(grouped_by_year[<!-- --><span class="hljs-string">&#x27;text&#x27;<!-- --></span>])
<!-- --></code></pre>
<!-- --><p>Now we need to find the most important word in comparison to other years.<!-- --></p>
<!-- --><pre><code class="hljs language-python">sorted_indices = (tfidf_this_year - tfidf_other_years).argsort()[::-<!-- --><span class="hljs-number">1<!-- --></span>]
df = pd.DataFrame({this_year: word_list.iloc[sorted_indices[:top_n]]})
<!-- --></code></pre>
<!-- --><h1>My contribution<!-- --></h1>
<!-- --><p>After the presentation I was super excited about the idea and wanted to try it out. When I first tried it, it only supported iPhones. I decided to add a Facebook Chat connector. It still has minor issues, such as an ID not being properly resolved, but it works (in fact all those charts above use my FB data).<!-- --></p>
<!-- --><p>I have also been looking into clustering. Having the word vectors would allow us to cluster our text/chat partners and see who we interact with similarly. I am still working on it, but below is how a first draft looks (names purposefully omitted).
<!-- --><img src="https://media.graphcms.com/Zn1uK6zpScGhzgdXFbvw" alt="clustered contacts"/></p>
<!-- --><h1>Check it out<!-- --></h1>
<!-- --><p>I&#x27;d recommend anybody to check out the repository. Michael has been awesome in reviewing my code and gave me so many helpful tips. You can find the repository <!-- --><a href="https://github.com/mdezube/sms-analysis">here<!-- --></a>.<!-- --></p><p class="MuiTypography-root MuiTypography-body1 css-1bw4yx3">Published on <!-- -->2018-02-14<!-- -->.<!-- --></p></div></div><hr class="border-accent-2 mt-28 mb-24"/><div><h4 class="MuiTypography-root MuiTypography-h4 css-1f04t6y">More Stories</h4><div class="MuiMasonry-root css-g8y262"><div><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation1 MuiCard-root css-s18byi"><img class="MuiCardMedia-root MuiCardMedia-media MuiCardMedia-img css-rhsghg"/><div class="MuiCardContent-root css-1qw96cp"><button class="MuiButtonBase-root MuiCardActionArea-root css-1jluznr" tabindex="0" type="button"><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineNone css-1tqdl5x" href="/posts/systemd-frustration"><div class="MuiBox-root css-k008qs"><div class="MuiBox-root css-i9gxme"><h4 class="MuiTypography-root MuiTypography-h4 css-1f04t6y">Systemd Services are frustratingly hard to make safe</h4></div><div class="MuiBox-root css-56sg73"><div class="MuiButtonBase-root MuiChip-root MuiChip-filled MuiChip-sizeMedium MuiChip-colorDefault MuiChip-clickable MuiChip-clickableColorDefault MuiChip-filledDefault css-genwvd" tabindex="0" href="/author/nigel-schuster"><div class="MuiAvatar-root MuiAvatar-circular MuiChip-avatar MuiChip-avatarMedium MuiChip-avatarColorDefault css-3i9vrz"><img alt="Nigel Schuster" src="https://media.graphassets.com/resize=fit:crop,height:100,width:100/1bF1qLxsSbElgNK5x6t6" class="MuiAvatar-img css-1hy9t21"/></div><span class="MuiChip-label MuiChip-labelMedium css-9iedg7">Nigel Schuster</span></div></div></div><p class="MuiTypography-root MuiTypography-body1 css-9l3uo3">This article takes a dive into what it takes to set up a systemd service with the principle of least privilege.</p></a><span class="MuiCardActionArea-focusHighlight css-jo3ec3"></span></button></div></div></div><div><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation1 MuiCard-root css-s18byi"><img class="MuiCardMedia-root MuiCardMedia-media MuiCardMedia-img css-rhsghg"/><div class="MuiCardContent-root css-1qw96cp"><button class="MuiButtonBase-root MuiCardActionArea-root css-1jluznr" tabindex="0" type="button"><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineNone css-1tqdl5x" href="/posts/variants-are-powerful"><div class="MuiBox-root css-k008qs"><div class="MuiBox-root css-i9gxme"><h4 class="MuiTypography-root MuiTypography-h4 css-1f04t6y">Variants are incredibly powerful</h4></div><div class="MuiBox-root css-56sg73"><div class="MuiButtonBase-root MuiChip-root MuiChip-filled MuiChip-sizeMedium MuiChip-colorDefault MuiChip-clickable MuiChip-clickableColorDefault MuiChip-filledDefault css-genwvd" tabindex="0" href="/author/nigel-schuster"><div class="MuiAvatar-root MuiAvatar-circular MuiChip-avatar MuiChip-avatarMedium MuiChip-avatarColorDefault css-3i9vrz"><img alt="Nigel Schuster" src="https://media.graphassets.com/resize=fit:crop,height:100,width:100/1bF1qLxsSbElgNK5x6t6" class="MuiAvatar-img css-1hy9t21"/></div><span class="MuiChip-label MuiChip-labelMedium css-9iedg7">Nigel Schuster</span></div></div></div><p class="MuiTypography-root MuiTypography-body1 css-9l3uo3">Variants are an incredibly powerful tool to express the state of your program!</p></a><span class="MuiCardActionArea-focusHighlight css-jo3ec3"></span></button></div></div></div></div></div></div></main></div><footer><div class="MuiContainer-root MuiContainer-maxWidthLg css-1qsxih2"><p class="MuiTypography-root MuiTypography-body1 css-9l3uo3">Built with NextJS. Find the source <!-- --><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-1c0wj8h" href="https://github.com/Neitsch/neitsch.github.io">here</a>.<!-- --></p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"__typename":"Post","title":"Messaging Analysis and Visualization","slug":"sms-analysis","content":"About a year ago I attended a [Meetup on D3.js](https://www.meetup.com/it-IT/NYC-D3-JS/events/236673854/). The first talk by [Michael Dezube](https://github.com/mdezube) was on using machine learning to analyze text messages and visualize the results. Today I want to walk through all the awesomeness we have in this project.\n\n# Demo\nThe first chart we see is this\n![texting per month](https://media.graphcms.com/BOw9T1zYQ4eUKUCZTK9d)\n\n\nHere it shows us our messaging habits over the years. Fascinating how it varies! But let's dive deeper. The important question is: Who did we message? We can display the top N people:\n![top people messaged with](https://media.graphcms.com/kr0XNn7cQY21lkD2C1te)\n\nBut who did we message and when?\n![people messaged over time](https://media.graphcms.com/pkGf8kxTnevn7OiELmvw)\n\nThis graph is great! It's almost a history of my life. Looking back at it, I can see when I made friendships and how they were developing. This is probably my favorite visualization!\n\nAfter that we have a word cloud and a tree for visualizing conversations, but it's a little too personal for me to post online.\n\nLater in the Jupyter notebook we find a chart that shows us our top words over the years, accounting for the relative frequency in other years:\n![words over the years](https://media.graphcms.com/bBSQzlOjSneomJ3MtO2C)\n\nHere we see me moving to the US, but also how I was interacting. The blacked out sections are names of people. Fascinating who I was talking about ðŸ˜‰.\n\nThis project has not seen any attention in the last months, but there is still so much more to explore.\n\n# How it works\nWe start by loading the data into our notebook\n```python\nimport iphone_connector\niphone_connector.initialize()\nfully_merged_messages_df, address_book_df = iphone_connector.get_cleaned_fully_merged_messages()\n```\nThe connector does all the heavy lifting. The iphone\\_connector accesses the latest iPhone backup and reads all text messages from its database. The facebook\\_connector uses fbchat\\_archive\\_parser to read a user's archive of chat messages. Now we have fully\\_merged\\_messages\\_df and address\\_book\\_df, both of which are [Pandas Dataframes](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html).\n\nOnce we have the messages we can create the heatmap. First we group our messages by month:\n```python\nmonth_year_messages = pd.DataFrame(df['date'])\nmonth_year_messages['year'] = month_year_messages.apply(lambda row: row.date.year, axis=1)\nmonth_year_messages['month'] = month_year_messages.apply(lambda row: row.date.month, axis=1)\n```\nThen we create a pivot table that contains the number of messages per month.\n```python\nmonth_year_messages_pivot = month_year_messages.pivot_table(index='year',columns='month',aggfunc=len, dropna=True)\nmonth_year_messages_pivot = month_year_messages_pivot[month_year_messages_pivot.count(axis=1) == 12]\n```\nAfter that we feed the data into the plotting tool.\n\nNext we want to create the barchart to see who we have messaged the most in the past. We group the messages by message partner and count how many you sent and received.\n```python\ndef get_message_counts(dataframe):\n    return pd.Series({\n      'Texts sent': dataframe[dataframe.is_from_me == 1].shape[0],\n      'Texts received': dataframe[dataframe.is_from_me == 0].shape[0],\n      'Texts exchanged': dataframe.shape[0]\n    })\nmessages_grouped = fully_merged_messages_df.groupby('full_name').apply(get_message_counts)\nmessages_grouped = messages_grouped.sort_values(by='Texts exchanged', ascending=False)\n```\nBy combining the ideas from the two charts above we can create the chart that shows our interactions with friends over time. We select our TOP\\_N friends and count how many messages we sent them each month.\n```python\nsliced_df = fully_merged_messages_df[fully_merged_messages_df.full_name.isin(messages_grouped.head(TOP_N).index)]\ngrouped_by_month = sliced_df.groupby([\n    sliced_df.apply(lambda x: x.date.strftime('%Y/%m'), axis=1),\n    'full_name']\n)['text'].count().to_frame()\n```\nAfter that we graph it using [D3.js](https://github.com/d3/d3).\n\nThe final chart - our most used words per year - requires us to dive into NLP. We'll be using Tfidf (term-frequency times inverse document-frequency) to calculate the relevance of each word.\n```python\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk import tokenize\nvectorizer = TfidfVectorizer(preprocessor=clean_text, tokenizer=tokenize.WordPunctTokenizer().tokenize, ngram_range=(1, 2), max_df=.9, max_features=50000)\ngrouped_by_name = fully_merged_messages_df[fully_merged_messages_df.is_from_me == 0].groupby('full_name')['text'].apply(lambda x: ' '.join(x)).to_frame()\nvectorizer.fit(grouped_by_name.text)\n```\nThe above code identifies the most relevant word for a certain chat partner, but important is, that it trains our TfidfVectorizer. We can now use it to find the prominence of a word in a given year.\n```python\ngrouper = slice_of_texts_df.date.apply(lambda x: x.year)\ngrouped_by_year = slice_of_texts_df.groupby(grouper).apply(\n  lambda row: pd.Series({'count': len(row.date), 'text': ' '.join(row.text)})\n)\ngrouped_by_year_tfidf = vectorizer.transform(grouped_by_year['text'])\n```\nNow we need to find the most important word in comparison to other years.\n```python\nsorted_indices = (tfidf_this_year - tfidf_other_years).argsort()[::-1]\ndf = pd.DataFrame({this_year: word_list.iloc[sorted_indices[:top_n]]})\n```\n\n# My contribution\nAfter the presentation I was super excited about the idea and wanted to try it out. When I first tried it, it only supported iPhones. I decided to add a Facebook Chat connector. It still has minor issues, such as an ID not being properly resolved, but it works (in fact all those charts above use my FB data).\n\nI have also been looking into clustering. Having the word vectors would allow us to cluster our text/chat partners and see who we interact with similarly. I am still working on it, but below is how a first draft looks (names purposefully omitted).\n![clustered contacts](https://media.graphcms.com/Zn1uK6zpScGhzgdXFbvw)\n\n# Check it out\nI'd recommend anybody to check out the repository. Michael has been awesome in reviewing my code and gave me so many helpful tips. You can find the repository [here](https://github.com/mdezube/sms-analysis).\n","date":"2018-02-14","ogImage":null,"coverImage":null,"author":{"__typename":"Author","name":"Nigel Schuster","slug":"nigel-schuster","picture":{"__typename":"Asset","url":"https://media.graphassets.com/resize=fit:crop,height:100,width:100/1bF1qLxsSbElgNK5x6t6"}}},"moreStories":[{"__typename":"Post","title":"Systemd Services are frustratingly hard to make safe","slug":"systemd-frustration","excerpt":"This article takes a dive into what it takes to set up a systemd service with the principle of least privilege.","coverImage":null,"author":{"__typename":"Author","name":"Nigel Schuster","slug":"nigel-schuster","picture":{"__typename":"Asset","url":"https://media.graphassets.com/resize=fit:crop,height:100,width:100/1bF1qLxsSbElgNK5x6t6"}}},{"__typename":"Post","title":"Variants are incredibly powerful","slug":"variants-are-powerful","excerpt":"Variants are an incredibly powerful tool to express the state of your program!","coverImage":null,"author":{"__typename":"Author","name":"Nigel Schuster","slug":"nigel-schuster","picture":{"__typename":"Asset","url":"https://media.graphassets.com/resize=fit:crop,height:100,width:100/1bF1qLxsSbElgNK5x6t6"}}}],"__typename":"Query"},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"sms-analysis"},"buildId":"5jr8GNds5__xtcSePFMSK","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>