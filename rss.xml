<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Nigel Schuster]]></title><description><![CDATA[Homepage/Blog of Nigel Schuster. This will mostly talk about various Software Engineering topics, such as Operating Systems or Machine Learning.]]></description><link>https://www.nigel-schuster.de</link><image><url>https://www.nigel-schuster.de/logos/logo-512.png</url><title>Nigel Schuster</title><link>https://www.nigel-schuster.de</link></image><generator>Nigel Schuster | Blog</generator><lastBuildDate>Mon, 26 Nov 2018 05:00:38 GMT</lastBuildDate><atom:link href="https://www.nigel-schuster.de/rss.xml" rel="self" type="application/rss+xml"/><author><![CDATA[Nigel Schuster]]></author><copyright><![CDATA[Copyright © 2018. Nigel Schuster]]></copyright><item><title><![CDATA[CRDTs - Sound good in theory, not in practice]]></title><description><![CDATA[This term I did some research on conflict-free replicated datatypes (CRDTs). I will walk through what they are, why the concept is cool, but…]]></description><link>https://www.nigel-schuster.de/articles/crd-ts-sound-good-in-theory-not-in-practice</link><guid isPermaLink="false">https://www.nigel-schuster.de/articles/crd-ts-sound-good-in-theory-not-in-practice</guid><category><![CDATA[Distributed Systems]]></category><category><![CDATA[CRDT]]></category><category><![CDATA[Conflict-Free Replicated Datatype]]></category><dc:creator><![CDATA[Nigel Schuster]]></dc:creator><pubDate>Sat, 05 May 2018 04:00:00 GMT</pubDate><content:encoded>&lt;p&gt;This term I did some research on conflict-free replicated datatypes (CRDTs). I will walk through what they are, why the concept is cool, but they don&apos;t work in practice.&lt;/p&gt;
&lt;h1 id=&quot;what-are-crdts&quot;&gt;&lt;a href=&quot;#what-are-crdts&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;What are CRDTs?&lt;/h1&gt;
&lt;p&gt;CRDT is a data structure that propagates concurrently in a network without the need for coordination.
CRDTs are mathematically proven to not cause inconsistencies.
This property is desirable, since all partitions of a split-brain scenario can continue accepting writes.
Since machines continue functioning independently, not all writes will immediately seen by all machines.
CRDTs are used in eventually consistent systems.&lt;/p&gt;
&lt;p&gt;Let&apos;s look at a concrete example of a CRDT: a simple counter (G-Counter).
To represent a counter we actually maintain N counters, where N is the number of machines.
Each machine independently increments its counter if it receives a write.
When two machines communicate each one sends along the latest values of all counters it knows of.
A machine then takes the max of the local value and the received value for each counter.
When a user reads the value of a counter, the system returns the sum of all counters.&lt;/p&gt;
&lt;p&gt;Based on similar concepts we can construct other similar data types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PN-Counter: A PN-Counter supports increments and decrements.
This is achieved by using two G-Counter, one keeps track of increments, the other one keeps track of decrements.&lt;/li&gt;
&lt;li&gt;G-Set: A G-Set is a set to which elements can be added to, but not removed.
Sets are propagates by taking the union of the local set with the received set.&lt;/li&gt;
&lt;li&gt;2P-Set: A 2P-Set allows for adding and removing items once.
Once a item was removed, it can not be added again.
A 2P-Set is achieved by maintaining a tombstone set.
The tombstone set indicates which elements to exclude from the return value.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another frequently used CRDT is a LWW-Set (Last-Write-Wins).
This data structure is able to handle repeated additions and removals by timestamping each change.
The timestamp is generated using vector clocks.
I personally do not like this data structure.
Vector clocks require consensus, consensus does not allow for a split-brain, and split-brain is a situation we fundamentally want to be able to handle with CRDTs.&lt;/p&gt;
&lt;h1 id=&quot;my-research&quot;&gt;&lt;a href=&quot;#my-research&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;My Research&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/raymondxu/&quot;&gt;Raymond&lt;/a&gt; and I wanted to test the viability of CRDTs in practice.
For this, we took an existing application and migrated components of it to a CRDT store.&lt;/p&gt;
&lt;p&gt;For this, we chose the application Vataxia, a simple social network with a Django backend. The &lt;a href=&quot;https://github.com/buckyroberts/Vataxia-Frontend&quot;&gt;frontend&lt;/a&gt; and &lt;a href=&quot;https://github.com/buckyroberts/Vataxia&quot;&gt;backend&lt;/a&gt; are completely decoupled. As our storage layer we chosee &lt;a href=&quot;docs.basho.com/riak/kv/2.2.3/learn/concepts/crdts/&quot;&gt;Riak&lt;/a&gt;, a well established CRDT store.&lt;/p&gt;
&lt;p&gt;We attempted to mirror the functionality provided by Vataxia originally. The two components we migrated are Voting and Messaging.&lt;/p&gt;
&lt;h2 id=&quot;voting&quot;&gt;&lt;a href=&quot;#voting&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Voting&lt;/h2&gt;
&lt;p&gt;Voting in Vataxia is simple. We broke it down into a few requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At most one Upvote or Downvote per user and post&lt;/li&gt;
&lt;li&gt;Vote removal must be possible&lt;/li&gt;
&lt;li&gt;No duplicate votes&lt;/li&gt;
&lt;li&gt;Only upvote OR downvote&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Take a minute and think about how you would implement it.
We considered the following options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using per post Counters: Counters sound simple and intuitive.
Counters do not check whether a user casted a duplicate vote, therefore this solution is not viable.&lt;/li&gt;
&lt;li&gt;Having a Set of voters per post: We considered using a G-Set, thereby eliminating the possibility of duplicate votes. This approach did not account for removing or changing one&apos;s vote.
We also considered using a 2P-Set, but this did not allow for the sequence upvote - remove vote - upvote.
This did not work either.
A LWW-Set fulfilled almost all requirements.
Yet, it did not work, because it did not allow to enforce only having an upvote OR a downvote, since we have to maintain a seperate upvote and downvote set.&lt;/li&gt;
&lt;li&gt;A map per post with key user and value vote: Each post maintans a LWW-Map. On each post the key of the map is the user ID, while the value is true or false (upvote / downvote, absence = no vote). This solution ended up being the only approach that was able to replicate the semantics of Vataxia.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;messaging&quot;&gt;&lt;a href=&quot;#messaging&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Messaging&lt;/h2&gt;
&lt;p&gt;In Vataxia messaging is akin to emails.
It does not allow for chats or threads.
Instead one sends individual messages that Vataxia treats completely separately.
The problems we faced here were different.
Implementing even a basic version was a lot harder.&lt;/p&gt;
&lt;p&gt;We chose to use the following system.
Our system maintains messages in a LLW-Map, where the key is the timestamp and the sender, while the value is the actual message.
A G-Set maintained on the user referrences his sent and received messages.
Note, that a G-Set is unordered, therefore we must address this on the application level.
To retrieve the latest messages we order the set on the user by timestamp and then fetch the latest messages.
This process can be expensive, since we load the identifier for every single message ever sent/received into memory and sort it.&lt;/p&gt;
&lt;h1 id=&quot;problems-of-crdts&quot;&gt;&lt;a href=&quot;#problems-of-crdts&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Problems of CRDTs&lt;/h1&gt;
&lt;p&gt;We notice, that the LWW-Map is a crucial component for both components we converted.
For me personally that is a deal breaker for CRDTs.
Since we rely so heavily on vector clocks, we rely on consensus.
CRDTs do not circumvent consensus in those cases and do not make the implementation easier.
Our implementations almost converged to the usage of a simple KeyValue-store, but with a more limited set of operations.&lt;/p&gt;
&lt;p&gt;The other major criticism for CRDTs is privacy.
If we do not use vector clocks, data that is written to the store will never be deleted.
Even a 2P-Set never truly deletes data, it merely marks it as hidden.
If an intruder gains access to the set, he/she can access the tombstone set and inspect deleted data.
Those semantics are at odds with the EU &quot;right to be forgotten&quot;.&lt;/p&gt;
&lt;h1 id=&quot;retrospective&quot;&gt;&lt;a href=&quot;#retrospective&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Retrospective&lt;/h1&gt;
&lt;p&gt;CRDTs are an interesting concept.
If an application can fit into the computational model of CRDTs excluding LWW semantics then CRDTs are a great options.
Almost no application can allow for those semantics.
The fact that deletion is often not possible is a crucial flaw.&lt;/p&gt;
&lt;h1 id=&quot;links&quot;&gt;&lt;a href=&quot;#links&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Links&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/raymondxu/crdt-project&quot;&gt;Repository&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.google.com/presentation/d/1i-AT59MD-DwwM-h1DFZUTj3qmx4_JYlojepA6IOauZI/edit?usp=sharing&quot;&gt;Midterm presentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.google.com/presentation/d/1i-AT59MD-DwwM-h1DFZUTj3qmx4_JYlojepA6IOauZI/edit?usp=sharing&quot;&gt;Final presentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/uploads/crdt-paper.pdf&quot;&gt;Final paper&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Lamport Clocks]]></title><description><![CDATA[I read Leslie Lamport's  Time, Clocks, and the Ordering of Events in a Distributed System . The paper is concise, yet profound and impactful…]]></description><link>https://www.nigel-schuster.de/articles/lamport-clocks</link><guid isPermaLink="false">https://www.nigel-schuster.de/articles/lamport-clocks</guid><category><![CDATA[Distributed Systems]]></category><category><![CDATA[Concurrency]]></category><category><![CDATA[Academic Writing]]></category><category><![CDATA[Synchronization]]></category><dc:creator><![CDATA[Nigel Schuster]]></dc:creator><pubDate>Tue, 20 Feb 2018 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I read Leslie Lamport&apos;s &lt;a href=&quot;https://lamport.azurewebsites.net/pubs/time-clocks.pdf&quot;&gt;&lt;em&gt;Time, Clocks, and the Ordering of Events in a Distributed System&lt;/em&gt;&lt;/a&gt;. The paper is concise, yet profound and impactful!!&lt;/p&gt;
&lt;h1 id=&quot;content&quot;&gt;&lt;a href=&quot;#content&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content&lt;/h1&gt;
&lt;p&gt;Lamport&apos;s paper is about the ordering of events.
His main goal is to provide an viable total ordering of events across machines based on a partial ordering.
He starts with baby steps, by looking at &lt;em&gt;before&lt;/em&gt; and &lt;em&gt;after&lt;/em&gt; as a temporal ordering in the context of events.
As he points out, determining whether one event occured before or after another one is not always possible due to the spacial distance of the machines.
What we instead focus on is &lt;em&gt;partial ordering&lt;/em&gt;.
This concept is about whether some event a must have occured before b given the information a system has.
If we know that a occured before b, then we say &quot;a --&gt; b&quot;, otherwise &quot;a --/&gt; b&quot;.
If &quot;a --/&gt; b&quot; and &quot;b --/&gt; a&quot;, then the events are concurrent.&lt;/p&gt;
&lt;p&gt;Now, we want to be able to have a order of events that all machines agree on and that respects partial ordering.
To achieve this, Lamport introduces &lt;em&gt;Logical Clocks&lt;/em&gt;.
Each time some event occurs on a machine (such as receiving a message), it increments its clock.
When two machines exchange a message, then the sender attaches timestamp.
The receiver sets its timestamp to be greater than the message timestamp.
With this, we can assign each event on a machine a timestamp.
When we propagate events to other machines in the system the receiver uses the this timestamp to determine the ordering.
The name of the machine generating the timestamp serves as tie breaker.&lt;/p&gt;
&lt;p&gt;With this simple setup we are able to introduce a total ordering in the system.
Note, that this setup disregards Machine failure and lost messages (both are non trivial to solve).&lt;/p&gt;
&lt;h1 id=&quot;writing&quot;&gt;&lt;a href=&quot;#writing&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Writing&lt;/h1&gt;
&lt;p&gt;The most fascinating part of the paper was not the result, but the way we obtained the result.
Lamport&apos;s style of writing is incredibly clear and concise.
Reading the paper is straightforward, yet the impact is profound.
This paper revolutionaized how we reason about events, time and synchronization.
I wish more academics write papers this well.&lt;/p&gt;
&lt;p&gt;P.S.: You can find my presentation on this topic &lt;a href=&quot;https://docs.google.com/presentation/d/1ElrYSbSfCI-ROX1p0QvQN5VWhsBcNSIHTYoR9QChVUI/edit#slide=id.p3&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Messaging Analysis and Visualization]]></title><description><![CDATA[About a year ago I attended a  Meetup on D3.js . The first talk by  Michael Dezube  was on using machine learning to analyze text messages…]]></description><link>https://www.nigel-schuster.de/articles/messaging-analysis-and-visualization</link><guid isPermaLink="false">https://www.nigel-schuster.de/articles/messaging-analysis-and-visualization</guid><category><![CDATA[Programming]]></category><category><![CDATA[NLP]]></category><category><![CDATA[Visualization]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[Past Project]]></category><dc:creator><![CDATA[Nigel Schuster]]></dc:creator><pubDate>Wed, 14 Feb 2018 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;About a year ago I attended a &lt;a href=&quot;https://www.meetup.com/it-IT/NYC-D3-JS/events/236673854/&quot;&gt;Meetup on D3.js&lt;/a&gt;. The first talk by &lt;a href=&quot;https://github.com/mdezube&quot;&gt;Michael Dezube&lt;/a&gt; was on using machine learning to analyze text messages and visualize the results. Today I want to walk through all the awesomeness we have in this project.&lt;/p&gt;
&lt;h1 id=&quot;demo&quot;&gt;&lt;a href=&quot;#demo&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Demo&lt;/h1&gt;
&lt;p&gt;The first chart we see is this

  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/86b3d9848a6783f0fbfcf3250110969c/4b2e7/sms-analysis-1.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 954px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 58.38574423480084%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAADCklEQVQoz22T228UZRjG5x/wLzChQkhMiPGiNyboHd4ZMZh4Soh4p4VooiYYjamoCYhaBIytoIhFCgba7s52Zs/ttLRbemBpy7Z7ohR2ty3tlumed7a7M/PzY2uCF1788r7f8873JE/ebySwgcb/YgtMW2BtV5s6ll0X/XZt9lYdW8yqRo1TXV4k0ywLMUnDjDUxzUQTS2jYd4Vx4gm20IgLYoIoWNHtKma1WolvftSQLKskhPn/sCDMFthqTJGtaJyJTHH0xjTfjk2yXB7GeT/E2cgEnfPjjGVHkce9HDvp5EFGp+OvGaSiUeD28i1mV8LMZERNTZKrTFPaCpLQezk0rPHi3xqv9QaZ1/v4+paHNwJBjoz6OTHn4dC5a+x4+SLheJZT7ijSZEpn1/dBdn0XYOcxL3s+H2A6I1MwZVIFmXtFmdWyk42Kg0eGg0B6AG9KpWYpvD80zO4Lo7ReDDG7XqBjbBHpZloYdoVo+UnjmXYPu9v62P/uWT76uZv2cIC3j1/jzT9U2kaGuJpUODHr40jAx8HfFPZ0arzQM8wXoSD38nk6IymksfgyT39yiZaP+3j2M4XnvlJo2X+Ol9qv8N7IIPvae3n1vJsPRPTLCYVfYx6Oah72dqgcuBrg0xEfl5JeHlby9NxdQgpNRnlq5zvsaD1O6+Fe9vlCvDI4Ttu4xuk5N9eXVCK6jF51sFJ2kBOxkzmZ32Mq0U2ZmayTnoSXrJFjaEVEXni4xlvdV3j+B5XXL/tx3VfwpxUm1lzigktEcYptB8SSRsjXfER1BceSwpdTPq4vqoRWZSIbCuX6pvg+gZQp6fyS9HPAq/HhDb8Q+8Uy+smU+nlQdAjDfpZLHtYqQdJFN+HsAO6Uiz9F/K55FeeSS+guDHOT9UoMKVfdYGJV5eTtQU7fGWRuw81iTiW++fiym5trHu488hDTVcLrKrNiHhV9uqhwfiFId9xPqugRhjmqjaR42LZJzTTIbxkUBHWrSuNf6pZBrVGhVM03z1vmE+qCUt0QUY3m7PHvZ9qr/ANUpCOKkEoPCwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;texting per month&quot;
        title=&quot;&quot;
        src=&quot;/static/86b3d9848a6783f0fbfcf3250110969c/4b2e7/sms-analysis-1.png&quot;
        srcset=&quot;/static/86b3d9848a6783f0fbfcf3250110969c/37099/sms-analysis-1.png 300w,
/static/86b3d9848a6783f0fbfcf3250110969c/f2478/sms-analysis-1.png 600w,
/static/86b3d9848a6783f0fbfcf3250110969c/4b2e7/sms-analysis-1.png 954w&quot;
        sizes=&quot;(max-width: 954px) 100vw, 954px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
Here it shows us our messaging habits over the years. Fascinating how it varies! But let&apos;s dive deeper. The important question is: Who did we message? We can display the top N people:

  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/b326bf83fada3d7ed8d7c9ae49b8d403/2fd0b/sms-analysis-2.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1165px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 58.11158798283261%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAAB70lEQVQoz52S/WvTQBzG89cKA/8BX2HDHzpxIr4UtcgclGq7DZ2jWsvYnMWxKaMwoTB12CR3yeU9sXEt2Hwf7zLWRhHfDj6575N8ee65y2nioAuxvwcnCOEIAcdx/hoh+13XxdGHI/R6PYRhCM1cqcJcvAMefwEzDDDGwDnP51N+p7nEYBy6riOKImhsrQ6jWskNuWnmzZZl5fMpf9K21Mo8jmOZ8MljeI8qsJOThMXGf8GUYfKE9rM6Wgs3cOhFEMz8LzOrmDBoNnD+7Cza7wV8e3pGE37WvzTkBcPnDVycmcO9VR2+ZYLZNkxLTA6cCwdMiOlCKk2eiP+g1ZZzw/DFMi7MzNH91T75gQ9z8yXCTpvcOCDuemCbLbg7WyRCqZVp/zM8bpAQFnEuf47eVzsjmZKiSCVcr9G5M7Mo12VjHJFVq9DSpXl0DuQ9iyJii7epfPk69j+6EGFIxsMyva3WcGh4sIKA9Ae3qFNr4BP3EctFtfTda9y8clesbVmjJE0Rv9nAtdLSqPnKzpJ0gHC7hVKpOmh3xDj5miLYWMf8fC3e3nXGyXEKt7mCqwuNdLfrZaPjATScjGWJwHR0JWlBtyRJQT+VDAp6RzJShUZyqEI9pzXFkm+qVHo4HO5lWTZZQH7zCTTG9IUyz1T5HUrXY/fhATJRAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;top people messaged with&quot;
        title=&quot;&quot;
        src=&quot;/static/b326bf83fada3d7ed8d7c9ae49b8d403/2fd0b/sms-analysis-2.png&quot;
        srcset=&quot;/static/b326bf83fada3d7ed8d7c9ae49b8d403/715e4/sms-analysis-2.png 300w,
/static/b326bf83fada3d7ed8d7c9ae49b8d403/fcbdd/sms-analysis-2.png 600w,
/static/b326bf83fada3d7ed8d7c9ae49b8d403/2fd0b/sms-analysis-2.png 1165w&quot;
        sizes=&quot;(max-width: 1165px) 100vw, 1165px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
But who did we message and when?

  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/10e5f2334114d2aaa588e029eb19ba12/2aea6/sms-analysis-3.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 1200px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 97.59229534510433%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABYlAAAWJQFJUiTwAAADxklEQVQ4y3WVW28bRRTH/a34DnwFkHhBFQ8g8YCEuLwgHpAqRC/kYiBUpQgqktCSENIqUlEoTUkTJ46bxpvYsb3e2F57vd7Ye/He999zZtet04qxxjO7O/7tmfn/z3HOtm04joMgCGCaJizLwmg0wkDXMaTRHJyL50mSgNtknJ57nic6t1yj0cBeoYBSqYRi8YB6EdVaDZqmQVVVSPUa+n0dcRz/L5ADqFarcF0POf5R+aiMsiTh8PAQDVlGrJ/zarHY6DURBf4LgPi8Ei3vskucMIyQUxQFhmFgOBzCGBiwXBd+6RiRHwBhgs2lJRi0RgBElInozJoGyhQIbzt3dnaGKIow3Yrr/8GX2+hbLj5bm4PcLIv7vO0UhAz6Eqh2OqRDSBES0PfTLUVhCl5efoTh/W2ocPFVZRZFbT8FEiSMAwSxl205PVcWskPAMCRgvV4XEwHMznt+bg3avW3oMHG98i0e6lvIiHQKDkHNTBW8ANZISCFKu90WluGHIj7HxicfzGP3cRXdSMWV01lsnN3HgbQD1R7xAoyCnqC5kZNt2UKv1xNHl2NVJxGK772neO/SZVy+egf7D37DNfUmbp/8grw0iyPrGAVNQc9VECc9aN52CjQtsP2EKC2FztAZ04tdRB0VTz7/Hm/O5PHp5ixub11DvnUT+foNrFa+wV/6BnaG99BxH2IY78FO1jGmSLvuQHg25AhlOkPfssl7Q8RHVSwVfsUbj29hx1jF7uAnzNUWMK/S9cpHaCy+C6v4MTznLpyTH5HIC9DbdyD/uQhFacEjcXPsn3DaNsEBPnx6HdKoBme8h5nTeaxat6D9/Dbw5SVgM09ufwJIj5CUV5D88wc6b72PptxMgSx3IGxDvmIXRBauVr7DM7sFMiPWla8hJavAzDuINxaR9CQkJ2vC5EmQ2qe/sASNjismX+ZY7okocZJ642/1d0i2TNHqqPSuoItd4IcvKJq75D0bkLcuph5lGosyHrtppgjbCGBq1P3zLZw6Nbrho2UskxvbwMoNJAf/UmQkg/psKhUJSNWo2+2mxmYfRlF4wfmKXYLhnYq549XIn+SCnQdIzvuAS17U5QtAx3bQosBcL6s2ky1PgKavUBoOsh/5aTk4LiDxXSSOSWAtvZcBuY6qFKGohxzhdI1L2wivNW/8cp69eNK4OLRarRTIKnPp4qpsWWY6jgYinXgh56lD6WjSXFxn3aHOkY3HY1GMucgKIJO5cy6yUgxn5fmaX9ZoyBgMBqhWKmLk+qlQdun0F8FVmsdms0nAtGA8B9yx00GtLu5ZAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;people messaged over time&quot;
        title=&quot;&quot;
        src=&quot;/static/10e5f2334114d2aaa588e029eb19ba12/abe1c/sms-analysis-3.png&quot;
        srcset=&quot;/static/10e5f2334114d2aaa588e029eb19ba12/10046/sms-analysis-3.png 300w,
/static/10e5f2334114d2aaa588e029eb19ba12/3c4a3/sms-analysis-3.png 600w,
/static/10e5f2334114d2aaa588e029eb19ba12/abe1c/sms-analysis-3.png 1200w,
/static/10e5f2334114d2aaa588e029eb19ba12/2aea6/sms-analysis-3.png 1246w&quot;
        sizes=&quot;(max-width: 1200px) 100vw, 1200px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
This graph is great! It&apos;s almost a history of my life. Looking back at it, I can see when I made friendships and how they were developing. This is probably my favorite visualization!&lt;/p&gt;
&lt;p&gt;After that we have a word cloud and a tree for visualizing conversations, but it&apos;s a little too personal for me to post online.&lt;/p&gt;
&lt;p&gt;Later in the Jupyter notebook we find a chart that shows us our top words over the years, accounting for the relative frequency in other years:

  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/2b106777dbb8e7dc4d57fbbc4ca4c12f/f77ec/sms-analysis-4.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 756px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 126.71957671957672%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAYAAAAxFw7TAAAACXBIWXMAABYlAAAWJQFJUiTwAAAEl0lEQVQ4y01VSXbbVhDkibLNDbzJNi8HyBW8yxVyiKyTTXwIPYkWxRkgQAwkZo7gKM5Ed6o+bTnaCAQ+uqurqgu15WKhy+VS4zjSer2ujuNq4/VVu92uPj09ab/f19Vqpc1mU3u9nvDa9319xZkoiuR4PGiSJPr8/KxhGGptPp9rWZZa5Lm2220dDj3tdjqmEF+yLFsPh4NYliW8xtlbEAQXnK3iONb7/S4LgGo23xT3tYaDpqPtOMq/BIeiKNYFUPs4sN6siVyC0UgulwvP/nG73T5VVeWzQKPRqJ5f6myq2+1Wa2mWGsjjcaSX69WMPh6NdDqdqTNwdIYJHMeRZVnK+36vg8Egm85m3vl8Po3GY/NsMpno6XQyk9byotAsTZXwKxFTPIrGWi5LGbqughKOe9/t97fj8SiOM9ANkAjOhkBt27ZuNhsFYsN1DR00QqcBHqzXa83BJWmAAOoOhzIHP0StKmasdqtV2ZZdAREaDrXV7gjfOwMhxa15nqdxFJmC8/nCIKRaaZoKr0H4GVz9u95s/gGSjW1bWhSFYGQjwgCAFoul8rcpSEGIgAXLco1CifpoUhQTmc1m5GWb5flv+93+F4w0JnLcq67Xi3Jc2ms2m/8oyC5UlmO+NRra6XR1Al5ZzHFdKVdrDdCU4uwhig37EDkKCMGAFnP/o6AZGQh9P+AoxkJjcArlxIUoUJSinJM0PWPiO1HR0OQwDAPlGYpy+s4h+YLCUkymFZivksSglTwvtNVsCkVig+12pwIlW+22QF1oJFgCF8vQ0ff3d73CcsY26CB5lqkLctkJowp9iEIyxDgg/HI8HD6j2a/g8G8WxxahcSIxFuDbFAqzPwoSIR4e8aCPgkWG4igkeNEUxO+bO3S/DD3vLyjfJjV4p4IjeMasKkf9GHk6nRKNneXZT4D+J7u0Ws2qj7GJPo4TTbNcIwhHi7Rb7ep4OBpEnjcEWkt3/xcFo6LTCEhyLjr5goop4UsHYYH0gSj9OwreoCZMbWFDxvShMECW5cOD2KJHQY4FzoTCnE5n/mdxetCM/BgLo0OczWbL3TXXHJF0Ma32EOWjoFk92OD166sgLSSGx+ovdYGdcO+riTCOxf/LZWliyrIHBpXv+fqCHKQjLpcztwqijELt97oaoBu7MDlCoGJo8Hq/fzfZWGLxWQRpYzx7Op50BDdwIQBIb6CLO21U5toFMCkdD3GUsUSk3IhVudIe1ovi0W8dhC+jjtd8l4tB/tnM2IZd6KXGW9OsFwXhQW4NLcGoouKTyZQNBQUFqCs6mzt/Bu8U84ND7jKjn13ZhfAdjBWGj0Ys6rgOtikRGp8CsSHfwxqKBX4ZceTwR8FWyyBjQaqMvDMFyZ0HvoLAFxoeBbnXW9wvEb43BgnOmm/KB0IPYUCEUBnRlSlCQEOg5DeFCOkz7i95RcDesMe/i8rP2F13UkxoowpbpC/4rnCabyr3lBwRIdbLJA659TAer7mKJRqQQ+RfCUQznL1yOqY6C+12u4dtOOIjXEuTGLQKclAfYjnGa7QKx+UngLHPrxtXbzQKhT5mJn7/6v0HZukYUPc6xPwAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;words over the years&quot;
        title=&quot;&quot;
        src=&quot;/static/2b106777dbb8e7dc4d57fbbc4ca4c12f/f77ec/sms-analysis-4.png&quot;
        srcset=&quot;/static/2b106777dbb8e7dc4d57fbbc4ca4c12f/f6d30/sms-analysis-4.png 300w,
/static/2b106777dbb8e7dc4d57fbbc4ca4c12f/3b26c/sms-analysis-4.png 600w,
/static/2b106777dbb8e7dc4d57fbbc4ca4c12f/f77ec/sms-analysis-4.png 756w&quot;
        sizes=&quot;(max-width: 756px) 100vw, 756px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
Here we see me moving to the US, but also how I was interacting. The blacked out sections are names of people. Fascinating who I was talking about 😉.&lt;/p&gt;
&lt;p&gt;This project has not seen any attention in the last months, but there is still so much more to explore.&lt;/p&gt;
&lt;h1 id=&quot;how-it-works&quot;&gt;&lt;a href=&quot;#how-it-works&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How it works&lt;/h1&gt;
&lt;p&gt;We start by loading the data into our notebook&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; iphone_connector
iphone_connector&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;initialize&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
fully_merged_messages_df&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; address_book_df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; iphone_connector&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;get_cleaned_fully_merged_messages&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The connector does all the heavy lifting. The iphone_connector accesses the latest iPhone backup and reads all text messages from its database. The facebook_connector uses fbchat_archive_parser to read a user&apos;s archive of chat messages. Now we have fully_merged_messages_df and address_book_df, both of which are &lt;a href=&quot;https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html&quot;&gt;Pandas Dataframes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once we have the messages we can create the heatmap. First we group our messages by month:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;month_year_messages &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;DataFrame&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;df&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;date&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
month_year_messages&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;year&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; month_year_messages&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; row&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; row&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;date&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;year&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; axis&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
month_year_messages&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;month&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; month_year_messages&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; row&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; row&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;date&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;month&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; axis&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then we create a pivot table that contains the number of messages per month.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;month_year_messages_pivot &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; month_year_messages&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;pivot_table&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;index&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;year&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;columns&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;month&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;aggfunc&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; dropna&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
month_year_messages_pivot &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; month_year_messages_pivot&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;month_year_messages_pivot&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;count&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;axis&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After that we feed the data into the plotting tool.&lt;/p&gt;
&lt;p&gt;Next we want to create the barchart to see who we have messaged the most in the past. We group the messages by message partner and count how many you sent and received.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;get_message_counts&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;dataframe&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Series&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;token string&quot;&gt;&apos;Texts sent&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; dataframe&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;dataframe&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;is_from_me &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;token string&quot;&gt;&apos;Texts received&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; dataframe&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;dataframe&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;is_from_me &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;token string&quot;&gt;&apos;Texts exchanged&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; dataframe&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;shape&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
messages_grouped &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; fully_merged_messages_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;groupby&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;full_name&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;get_message_counts&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
messages_grouped &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; messages_grouped&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;sort_values&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;by&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;Texts exchanged&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ascending&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By combining the ideas from the two charts above we can create the chart that shows our interactions with friends over time. We select our TOP_N friends and count how many messages we sent them each month.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;sliced_df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; fully_merged_messages_df&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;fully_merged_messages_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;full_name&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;isin&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;messages_grouped&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;head&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;TOP_N&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;index&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
grouped_by_month &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; sliced_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;groupby&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;
    sliced_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;date&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;strftime&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;%Y/%m&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; axis&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;token string&quot;&gt;&apos;full_name&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;text&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;count&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;to_frame&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After that we graph it using &lt;a href=&quot;https://github.com/d3/d3&quot;&gt;D3.js&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The final chart - our most used words per year - requires us to dive into NLP. We&apos;ll be using Tfidf (term-frequency times inverse document-frequency) to calculate the relevance of each word.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; sklearn&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;feature_extraction&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;text &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; TfidfVectorizer
&lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; nltk &lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; tokenize
vectorizer &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; TfidfVectorizer&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;preprocessor&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;clean_text&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; tokenizer&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;tokenize&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;WordPunctTokenizer&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;tokenize&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ngram_range&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; max_df&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;.9&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; max_features&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
grouped_by_name &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; fully_merged_messages_df&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;fully_merged_messages_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;is_from_me &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;groupby&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;full_name&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;text&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos; &apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;join&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;to_frame&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
vectorizer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;fit&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;grouped_by_name&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;text&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above code identifies the most relevant word for a certain chat partner, but important is, that it trains our TfidfVectorizer. We can now use it to find the prominence of a word in a given year.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;grouper &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; slice_of_texts_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;date&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;year&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
grouped_by_year &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; slice_of_texts_df&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;groupby&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;grouper&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token builtin&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;token keyword&quot;&gt;lambda&lt;/span&gt; row&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Series&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;count&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token builtin&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;row&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;date&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;text&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos; &apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;join&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;row&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;text&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
grouped_by_year_tfidf &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; vectorizer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;transform&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;grouped_by_year&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&apos;text&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we need to find the most important word in comparison to other years.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;language-python&quot;&gt;&lt;code class=&quot;language-python&quot;&gt;sorted_indices &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;tfidf_this_year &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt; tfidf_other_years&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;argsort&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
df &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; pd&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;DataFrame&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;this_year&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; word_list&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;iloc&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;sorted_indices&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;top_n&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id=&quot;my-contribution&quot;&gt;&lt;a href=&quot;#my-contribution&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;My contribution&lt;/h1&gt;
&lt;p&gt;After the presentation I was super excited about the idea and wanted to try it out. When I first tried it, it only supported iPhones. I decided to add a Facebook Chat connector. It still has minor issues, such as an ID not being properly resolved, but it works (in fact all those charts above use my FB data).&lt;/p&gt;
&lt;p&gt;I have also been looking into clustering. Having the word vectors would allow us to cluster our text/chat partners and see who we interact with similarly. I am still working on it, but below is how a first draft looks (names purposefully omitted).

  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/f645965c9d3ae51c090702637ea54822/d6fae/sms-analysis-5.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 963px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 52.232606438213914%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABrElEQVQoz1VSW3LbMAzU/W/R/mcmPUP9kyYdN2kVR7JEUXyAkmyfYbsA1ST94AAChcXugs3tdsO6rti21WLNN2yMyyLIS+T35b+7z/Fz7/V6RaNJjBFZCnLOSCnCxwlpnhDdG+/mvZ6QGP/l7zXLxWIpBY1Oylpks/40hQExB9Y4xJ+RZwfhj/YPa6J1BcgVVEQwJw5nfV1WNBfK8XFEmnprmskuJF8BCVaZU3rwSH6oA2SBD6OBaD7OnRFZ100lbxhHnSA2TWmHoHLyzoxRpfJOj5QKZnkMNiBJgvMdezOahTSffw0EDfBTPXGOSDGxIX0A7f7piSmYZPOXqnSIel5Yby6XDcPgcTwOcCcuox0RXgYEAguB86QsIkJRlsq6KlFQXZ4EghJYWZdlqUvRDbWtw4mn7+gfY/7eQr4cIN+eIC+qgLU3h9B7RB/4pIoBC/09dw/w/REL92HPpq5cTHb/mws6tMh3PyBfD0j3j8hP9IeD0vMZw6tD+2e0wdEsKZQ7mmS1rz6bff02lXmYuL2OnriAmeyUofvZw71WBSda433cGWbzUH1eKfkvn+fZ0OKV03QAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;clustered contacts&quot;
        title=&quot;&quot;
        src=&quot;/static/f645965c9d3ae51c090702637ea54822/d6fae/sms-analysis-5.png&quot;
        srcset=&quot;/static/f645965c9d3ae51c090702637ea54822/74412/sms-analysis-5.png 300w,
/static/f645965c9d3ae51c090702637ea54822/4a056/sms-analysis-5.png 600w,
/static/f645965c9d3ae51c090702637ea54822/d6fae/sms-analysis-5.png 963w&quot;
        sizes=&quot;(max-width: 963px) 100vw, 963px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;h1 id=&quot;check-it-out&quot;&gt;&lt;a href=&quot;#check-it-out&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Check it out&lt;/h1&gt;
&lt;p&gt;I&apos;d recommend anybody to check out the repository. Michael has been awesome in reviewing my code and gave me so many helpful tips. You can find the repository &lt;a href=&quot;https://github.com/mdezube/sms-analysis&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Trying to build a good web app]]></title><description><![CDATA[Motivation We built our project "MIWF" during our Advanced Software Engineering class.
We wanted to build an application that allowed people…]]></description><link>https://www.nigel-schuster.de/articles/trying-to-build-a-good-web-app</link><guid isPermaLink="false">https://www.nigel-schuster.de/articles/trying-to-build-a-good-web-app</guid><category><![CDATA[Programming]]></category><category><![CDATA[Software Engineering]]></category><category><![CDATA[Past Project]]></category><dc:creator><![CDATA[Nigel Schuster]]></dc:creator><pubDate>Sun, 11 Feb 2018 05:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;motivation&quot;&gt;&lt;a href=&quot;#motivation&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h1&gt;
&lt;p&gt;We built our project &quot;MIWF&quot; during our Advanced Software Engineering class.
We wanted to build an application that allowed people to simulate stock trading.
This hypothetical product would target people who have no experience in
stock trading and want to get involved.&lt;/p&gt;
&lt;h1 id=&quot;software-stack&quot;&gt;&lt;a href=&quot;#software-stack&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Software Stack&lt;/h1&gt;
&lt;p&gt;We tried to decide on components that fit our experience and are appropriate
for the project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Database: We picked &lt;a href=&quot;https://www.postgresql.org/&quot;&gt;PostgreSQL&lt;/a&gt; as our database.
We knew that a relational database was the best decision,
since our data fits well in a schema, required a lot of aggregation
queries, and the database is widely deployed. Our decision fell on PostgreSQL
over MySQL, since we had more operational experience with former.&lt;/li&gt;
&lt;li&gt;Backend: We powered our backend with &lt;a href=&quot;https://www.djangoproject.com/&quot;&gt;Django&lt;/a&gt;.
Python was a language that we all had worked with before, thus that
part was an easy decision. Then we could have either gone with Flask + SQLAlchemy
or Django. We chose latter, since it offered more of a all-in-one solution and
thus made it easier for our team. Also Django has an awesome [documentation]
(&lt;a href=&quot;https://docs.djangoproject.com/en/2.0/&quot;&gt;https://docs.djangoproject.com/en/2.0/&lt;/a&gt;)!&lt;/li&gt;
&lt;li&gt;API: We exposed our data via &lt;a href=&quot;http://graphql.org/&quot;&gt;GraphQL&lt;/a&gt;. It allowed us to
manage our data definitions in an easier way. On top of that [Graphene]
(&lt;a href=&quot;http://graphene-python.org/&quot;&gt;http://graphene-python.org/&lt;/a&gt;) allowed us to parallelize a lot of data fetching.
On the client side it allowed us to evolve our data needs with [Relay]
(&lt;a href=&quot;https://facebook.github.io/relay/&quot;&gt;https://facebook.github.io/relay/&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Frontend: We used &lt;a href=&quot;https://reactjs.org/&quot;&gt;React&lt;/a&gt; to manage our view layer. It
allowed us to work well with user interactions. Paired with [Relay]
(&lt;a href=&quot;https://facebook.github.io/relay/&quot;&gt;https://facebook.github.io/relay/&lt;/a&gt;), we were able to model user data and
interaction well. The declarative style allowed us to reason about
the data.&lt;/li&gt;
&lt;li&gt;Documentation: We generated our documentation with Sphinx and deployed it to readthedocs. You can find it &lt;a href=&quot;http://ase4156.readthedocs.io/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;External Services: We integrated our application with some external services
to move critical data away from our responsibility.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://plaid.com/&quot;&gt;Plaid&lt;/a&gt;: This API allowed us to integrate with real
production data. Users were able to link our application with their real bank
account.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://developers.google.com/identity/sign-in/web/sign-in&quot;&gt;Google Auth&lt;/a&gt;:
We did not want to take the responsibility of authenticating the user, since
we would have to store the password and prevent attacks. Thus instead we went
with Google Authentication. Integrating with the tool was a breeze.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Testing: A major focus of the class was properly testing the application. We
were able to achieve a 96% test coverage.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python: Django offered an [internal testing tool]
(&lt;a href=&quot;https://docs.djangoproject.com/en/2.0/topics/testing/overview/&quot;&gt;https://docs.djangoproject.com/en/2.0/topics/testing/overview/&lt;/a&gt;), but [pytest]
(&lt;a href=&quot;https://docs.pytest.org/en/latest/&quot;&gt;https://docs.pytest.org/en/latest/&lt;/a&gt;) had a better appeal for us, since the test runner is
widely used. Pytest was not always easy to integrate with Django, but it ended up
working for our use cases.&lt;/li&gt;
&lt;li&gt;Javascript: We used &lt;a href=&quot;https://facebook.github.io/jest/&quot;&gt;Jest&lt;/a&gt; to test the
Javascript side of our application. Combined with [Snapshot Testing]
(&lt;a href=&quot;https://facebook.github.io/jest/docs/en/snapshot-testing.html&quot;&gt;https://facebook.github.io/jest/docs/en/snapshot-testing.html&lt;/a&gt;) we were able
to test our client side well. We struggled with testing Relay
components. Ultimately we had to add a lot of extra test data to
match the expected fragments. An example testcase is [here]
(&lt;a href=&quot;https://github.com/Neitsch/ASE4156/blob/master/web/js/components/InvestBucket/__tests__/InvestBucketRelay-test.jsx&quot;&gt;https://github.com/Neitsch/ASE4156/blob/master/web/js/components/InvestBucket/&lt;strong&gt;tests&lt;/strong&gt;/InvestBucketRelay-test.jsx&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Selenium: This served as one of our pillars to verify that our software
actually worked. Unit and integration testing took us 90% of the way, but
Selenium caught regressions throughout our development process.
It ended up being an important asset.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Infrastructure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We hosted our database with [GCP SQL]
(&lt;a href=&quot;https://cloud.google.com/sql/docs/postgres/&quot;&gt;https://cloud.google.com/sql/docs/postgres/&lt;/a&gt;), since we had credits there.&lt;/li&gt;
&lt;li&gt;We did CID through &lt;a href=&quot;https://travis-ci.org/&quot;&gt;Travis&lt;/a&gt;, since we had positive
experiences with it in the
past&lt;/li&gt;
&lt;li&gt;We hosted our application in &lt;a href=&quot;http://dashboard.heroku.com/&quot;&gt;Heroku&lt;/a&gt;, since
it seamlessly integrated with Travis and managed our application well.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;final-result&quot;&gt;&lt;a href=&quot;#final-result&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Final result&lt;/h1&gt;
&lt;p&gt;I am satisfied with the final result. All our code is in our &lt;a href=&quot;https://github.com/Neitsch/ASE4156&quot;&gt;Github
Repository&lt;/a&gt;. We have good test coverage
with 96% coverage. Our code is well documented and met most of anticipated
goals. Big thanks to JP Morgan Chase and Will Searle for mentoring us
throughout the project. We made 2nd place at a private competition for our class.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Capsule Networks]]></title><description><![CDATA[Capsule Networks are a novel approach for processing data with a neural network.
They were first introduced a couple years ago, but gained…]]></description><link>https://www.nigel-schuster.de/articles/capsule-networks</link><guid isPermaLink="false">https://www.nigel-schuster.de/articles/capsule-networks</guid><category><![CDATA[Programming]]></category><category><![CDATA[Neural Networks]]></category><category><![CDATA[Machine Learning]]></category><category><![CDATA[Past Project]]></category><dc:creator><![CDATA[Nigel Schuster]]></dc:creator><pubDate>Sat, 10 Feb 2018 05:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Capsule Networks are a novel approach for processing data with a neural network.
They were first introduced a couple years ago, but gained some
popularity after Hinton et al. published [Dynamic Routing between Capsules]
(&lt;a href=&quot;https://arxiv.org/abs/1710.09829&quot;&gt;https://arxiv.org/abs/1710.09829&lt;/a&gt;). We researched the performance of CapsNets
during our Deep Learning class. Our main findings were, that CapsNets exhibit
some desirable properties, such as resistance to Adversarial Attacks and
better adaptiveness, but are orders of magnitude slower. You can find
the full report &lt;a href=&quot;/uploads/capsnets.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Welcome to my Blog]]></title><description><![CDATA[Motivation I've decided to start a blog for two purposes: First, I want to document my
work, so that I can go back, reflect and learn from…]]></description><link>https://www.nigel-schuster.de/articles/welcome-to-my-blog</link><guid isPermaLink="false">https://www.nigel-schuster.de/articles/welcome-to-my-blog</guid><category><![CDATA[Blog]]></category><category><![CDATA[Nigel Schuster]]></category><dc:creator><![CDATA[Nigel Schuster]]></dc:creator><pubDate>Fri, 09 Feb 2018 05:00:00 GMT</pubDate><content:encoded>&lt;h1 id=&quot;motivation&quot;&gt;&lt;a href=&quot;#motivation&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motivation&lt;/h1&gt;
&lt;p&gt;I&apos;ve decided to start a blog for two purposes: First, I want to document my
work, so that I can go back, reflect and learn from my mistakes. Second,
others can hopefully profit from my posts. I&apos;ve received so much guidance
from other blogs, now I hope to impart some of my experiences to others.&lt;/p&gt;
&lt;h1 id=&quot;content&quot;&gt;&lt;a href=&quot;#content&quot; aria-hidden class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Content&lt;/h1&gt;
&lt;p&gt;This blog will cover a wide range of Software Engineering topics. I&apos;ve tried
out programming languages ranging from Pascal to ReasonML and my interests are
as widely spread. Hopefully I&apos;ll be able to cover a wide range of topics
including OS development, frontend development and machine learning.&lt;/p&gt;</content:encoded></item></channel></rss>